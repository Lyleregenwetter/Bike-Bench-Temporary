{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe24ff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lyler\\mambaforge\\envs\\torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "import biked_commons\n",
    "from biked_commons.design_evaluation.design_evaluation import get_standard_evaluations\n",
    "from biked_commons.resource_utils import split_datasets_path\n",
    "from biked_commons.conditioning import conditioning\n",
    "\n",
    "from biked_commons.design_evaluation.scoring import *\n",
    "from biked_commons.benchmark_models import benchmarking_utils\n",
    "from biked_commons.transformation.one_hot_encoding import encode_to_continuous, decode_to_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b335ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(split_datasets_path(\"bike_bench.csv\"), index_col=0)\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "079640a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition(idx=0):\n",
    "    rider_condition = conditioning.sample_riders(10, split=\"test\")\n",
    "    use_case_condition = conditioning.sample_use_case(10, split=\"test\")\n",
    "    image_embeddings = conditioning.sample_image_embedding(10, split=\"test\")\n",
    "    condition = {\"Rider\": rider_condition[idx], \"Use Case\": use_case_condition[idx], \"Embedding\": image_embeddings[idx]}\n",
    "    return condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f79c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pymoo.core.problem import Problem\n",
    "# from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "# from pymoo.optimize import minimize\n",
    "# class BikeBenchProblem(Problem):\n",
    "#     def __init__(self, data_sample_df, conditioning):\n",
    "#         evaluator, requirement_names, requirement_types = construct_tensor_evaluator(get_standard_evaluations(\"cpu\"), data_sample_df.columns)\n",
    "#         data_sample = data_sample_df.to_numpy()\n",
    "        \n",
    "#         self.conditioning = conditioning\n",
    "\n",
    "#         self.evaluator=evaluator\n",
    "#         self.requirement_names=requirement_names\n",
    "#         isobjective = torch.tensor(requirement_types) == 1\n",
    "#         self.isobjective = isobjective\n",
    "\n",
    "#         n_var = data_sample.shape[1]\n",
    "#         n_obj = torch.sum(isobjective)\n",
    "#         n_ieq_constr = torch.sum(~isobjective)\n",
    "#         xl = np.quantile(data_sample, 0.01, axis=0)\n",
    "#         xu = np.quantile(data_sample, 0.99, axis=0)\n",
    "#         super().__init__(n_var=n_var, n_obj=n_obj, n_ieq_constr=n_ieq_constr, xl=xl, xu=xu)\n",
    "\n",
    "#     def evaluate_fn(self, X):\n",
    "#         X_tens = torch.tensor(X, dtype=torch.float32)\n",
    "#         eval_scores = self.evaluator(X_tens, self.conditioning)\n",
    "#         objective_scores = eval_scores[:, self.isobjective].detach().numpy()\n",
    "#         constraint_scores = eval_scores[:, ~self.isobjective].detach().numpy()\n",
    "#         return objective_scores, constraint_scores\n",
    "\n",
    "#     def _evaluate(self, x, out, *args, **kwargs):\n",
    "#         objective_scores, constraint_scores = self.evaluate_fn(x)\n",
    "#         out[\"F\"] = objective_scores\n",
    "#         out[\"G\"] = constraint_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab2245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.variable import Real, Integer, Choice, Binary\n",
    "\n",
    "\n",
    "class BikeBenchProblem(ElementwiseProblem):\n",
    "    def __init__(self,\n",
    "                 data_sample_df: pd.DataFrame,   # your one-hot–encoded df\n",
    "                 conditioning: dict,\n",
    "                 **kwargs):\n",
    "        # 1) keep around the original continuous columns for the evaluator:\n",
    "        self.continuous_cols = list(data_sample_df.columns)\n",
    "\n",
    "        # 2) build your evaluator as before:\n",
    "        evaluator, requirement_names, requirement_types = construct_tensor_evaluator(\n",
    "            get_standard_evaluations(\"cpu\"),\n",
    "            self.continuous_cols\n",
    "        )\n",
    "        self.evaluator      = evaluator\n",
    "        is_obj              = torch.tensor(requirement_types) == 1\n",
    "        self.isobjective    = is_obj\n",
    "        n_obj               = int(is_obj.sum().item())\n",
    "        n_ieq_constr        = int((~is_obj).sum().item())\n",
    "        self.conditioning   = conditioning\n",
    "\n",
    "        # 3) decode the ONE-HOT df into a mixed-type df for variable inference:\n",
    "        mixed_df = decode_to_mixed(data_sample_df)\n",
    "\n",
    "        # 4) infer each variable from its mixed dtype\n",
    "        vars = {}\n",
    "        for col in mixed_df.columns:\n",
    "            series = mixed_df[col]\n",
    "            if pd.api.types.is_bool_dtype(series):\n",
    "                vars[col] = Binary()\n",
    "            elif pd.api.types.is_integer_dtype(series):\n",
    "                low, high    = int(series.min()), int(series.max())\n",
    "                vars[col]    = Integer(bounds=(low, high))\n",
    "            elif pd.api.types.is_float_dtype(series):\n",
    "                # use your desired quantiles for bounds\n",
    "                low, high    = np.quantile(series, 0.01), np.quantile(series, 0.99)\n",
    "                vars[col]    = Real(bounds=(float(low), float(high)))\n",
    "            else:\n",
    "                # categorical / object\n",
    "                opts             = series.dropna().unique().tolist()\n",
    "                vars[col]        = Choice(options=opts)\n",
    "        super().__init__(\n",
    "            vars=vars,\n",
    "            n_obj=n_obj,\n",
    "            n_ieq_constr=n_ieq_constr,\n",
    "            **kwargs                                 \n",
    "        )\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        # X is a dict: { col_name: mixed_value }\n",
    "        # 1) build a one-row DataFrame in the mixed space\n",
    "        mixed_row = pd.DataFrame([X], columns=self.vars.keys())\n",
    "\n",
    "        # 2) encode it back to continuous one-hot form\n",
    "        cont_row  = encode_to_continuous(mixed_row)\n",
    "\n",
    "        # 3) ensure the columns line up exactly with the original one-hot df\n",
    "        cont_row  = cont_row[self.continuous_cols]\n",
    "\n",
    "        # 4) to numpy → tensor\n",
    "        x_np      = cont_row.to_numpy().astype(np.float32)\n",
    "        x_t       = torch.tensor(x_np, dtype=torch.float32)\n",
    "\n",
    "        # 5) evaluate\n",
    "        scores    = self.evaluator(x_t, self.conditioning)\n",
    "\n",
    "        # 6) split objectives vs constraints\n",
    "        f = scores[:,   self.isobjective ].detach().numpy().flatten().tolist()   # ← as list\n",
    "        g = scores[:, (~self.isobjective) ].detach().numpy().flatten().tolist()\n",
    "\n",
    "        out[\"F\"] = f\n",
    "        out[\"G\"] = g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2727f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================\n",
      "n_gen  |  n_eval  |     cv_min    |     cv_avg    |     f_avg     |     f_min    \n",
      "=================================================================================\n",
      "     1 |      100 |  0.000000E+00 |  1.444215E+02 |  0.4683860011 |  0.6532621384\n",
      "     2 |      200 |  0.000000E+00 |  2.262144E+01 |  0.4825900688 |  0.6532621384\n",
      "     3 |      300 |  0.000000E+00 |  0.6577757210 |  0.4568853946 |  0.6532621384\n",
      "     4 |      400 |  0.000000E+00 |  0.1347773373 |  0.4491379036 |  0.6532621384\n",
      "     5 |      500 |  0.000000E+00 |  0.000000E+00 |  0.4357045433 |  0.6532621384\n",
      "     6 |      600 |  0.000000E+00 |  0.000000E+00 |  0.4316216618 |  0.3342646360\n",
      "     7 |      700 |  0.000000E+00 |  0.000000E+00 |  0.4284055734 |  0.5461795926\n",
      "     8 |      800 |  0.000000E+00 |  0.000000E+00 |  0.4173671034 |  0.2564312518\n",
      "     9 |      900 |  0.000000E+00 |  0.000000E+00 |  0.4098626865 |  0.5983542204\n",
      "    10 |     1000 |  0.000000E+00 |  0.000000E+00 |  0.4175667900 |  0.3933217525\n"
     ]
    }
   ],
   "source": [
    "from pymoo.core.mixed import MixedVariableGA\n",
    "from pymoo.algorithms.moo.nsga2 import RankAndCrowdingSurvival\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "for i in range(1):\n",
    "    condition = get_condition(i)\n",
    "    problem = BikeBenchProblem(data, condition)\n",
    "\n",
    "    algorithm = MixedVariableGA(pop_size=100, survival = RankAndCrowdingSurvival())\n",
    "\n",
    "    res = minimize(problem, algorithm, ('n_gen', 10), seed=1, verbose=True)\n",
    "    mixed_df = pd.DataFrame(list(res.X)  , columns=problem.vars.keys())\n",
    "    res_df_onehot = encode_to_continuous(mixed_df)\n",
    "    results_tens = torch.tensor(res_df_onehot.values, dtype=torch.float32)\n",
    "    benchmarking_utils.evaluate_uncond(results_tens, \"NSGA2\", i, data.columns, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f83ca8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.DataFrame(result_tens.numpy(), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01c180f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from biked_commons.api import rendering\n",
    "# renderer = rendering.RenderingEngine(number_rendering_servers = 1, server_init_timeout_seconds=120)\n",
    "\n",
    "# res1 = result_df.iloc[0]\n",
    "# res = renderer.render_clip(res1)\n",
    "# svg = res.image_bytes\n",
    "# from IPython.display import SVG, display\n",
    "# display(SVG(svg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8ab00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
